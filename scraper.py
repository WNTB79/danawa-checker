import asyncio
from playwright.async_api import async_playwright
from bs4 import BeautifulSoup
from datetime import datetime
import gspread
import json
import os

SH_ID = "1hKx0tg2jkaVswVIfkv8jbqx0QrlRkftFtjtVlR09cLQ" 
MAX_ROWS = 10000

# ì œê³µí•´ì£¼ì‹  êµ¬ì„±ë³„ URL ë¦¬ìŠ¤íŠ¸
URL_LIST = [
    "https://prod.danawa.com/info/?pcode=13412984", # 1ê°œì…
    "https://prod.danawa.com/info/?pcode=13413059", # 2ê°œì…
    "https://prod.danawa.com/info/?pcode=13413086", # 3ê°œì…
    "https://prod.danawa.com/info/?pcode=13413254", # 4ê°œì…
    "https://prod.danawa.com/info/?pcode=13678937", # 5ê°œì…
    "https://prod.danawa.com/info/?pcode=13413314"  # 6ê°œì…
]

async def get_danawa_data():
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        context = await browser.new_context(
            viewport={'width': 1920, 'height': 1080},
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"
        )
        page = await context.new_page()
        
        now_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        # ê²°ê³¼ ë§¤íŠ¸ë¦­ìŠ¤ ì´ˆê¸°í™” (5í–‰ x 8ì—´: ë‚ ì§œ, ìˆœìœ„, 1~6ê°œì… ê°€ê²©)
        final_matrix = [[now_str, f"{i}ìœ„"] for i in range(1, 6)]

        # êµ¬ì„±ë³„ ì£¼ì†Œë¥¼ ì§ì ‘ ìˆœíšŒí•˜ë©° ìˆ˜ì§‘
        for idx, url in enumerate(URL_LIST, 1):
            try:
                print(f"ğŸš€ {idx}ê°œì… í˜ì´ì§€ ì ‘ì† ì¤‘...")
                await page.goto(url, wait_until="load", timeout=60000)
                # ë‹¤ë‚˜ì™€ ë³´ì•ˆ ê°ì§€ë¥¼ í”¼í•˜ê³  ë Œë”ë§ì„ ê¸°ë‹¤ë¦¬ê¸° ìœ„í•œ ì¶©ë¶„í•œ ëŒ€ê¸°
                await asyncio.sleep(8) 
                
                # ë°ì´í„° í™œì„±í™”ë¥¼ ìœ„í•œ ìŠ¤í¬ë¡¤
                await page.evaluate("window.scrollTo(0, 1100)")
                await asyncio.sleep(2)

                content = await page.content()
                soup = BeautifulSoup(content, 'html.parser')
                
                # ìš°ì¸¡ ê°€ê²© ë¹„êµ ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ (ë‹¤ì–‘í•œ ì„ íƒì ëŒ€ì‘)
                items = soup.select("#lowPrice_r .diff_item") or \
                        soup.select(".pay_comparison_list:not(.free_delivery) .diff_item") or \
                        soup.select(".diff_item")

                print(f"   ã„´ {idx}ê°œì… ë°ì´í„° ë°œê²¬: {len(items)}ê±´")

                for i in range(5):
                    if i < len(items):
                        p_tag = items[i].select_one(".prc_c")
                        price = p_tag.get_text().replace(",", "").replace("ì›", "").strip() if p_tag else "0"
                        final_matrix[i].append(price)
                    else:
                        final_matrix[i].append("-")

            except Exception as e:
                print(f"âš ï¸ {idx}ê°œì… ìˆ˜ì§‘ ì—ëŸ¬: {e}")
                for i in range(5): final_matrix[i].append("-")

        # --- êµ¬ê¸€ ì‹œíŠ¸ ì €ì¥ ---
        # ì‹¤ì œ ê°€ê²© ë°ì´í„°ê°€ í•˜ë‚˜ë¼ë„ ë“¤ì–´ìˆëŠ”ì§€ í™•ì¸ (3ë²ˆì§¸ ì—´ë¶€í„° ê°€ê²©)
        has_data = any(row[2] != "-" for row in final_matrix)
        
        if has_data:
            try:
                creds_raw = os.environ.get('GCP_CREDENTIALS', '').strip()
                creds = json.loads(creds_raw)
                gc = gspread.service_account_from_dict(creds)
                sh = gc.open_by_key(SH_ID)
                wks = sh.get_worksheet(0)
                
                # ê°€ë¡œë¡œ ì™„ì„±ëœ 5ì¤„ì„ í•œêº¼ë²ˆì— ì‹œíŠ¸ ìƒë‹¨(2í–‰)ì— ì‚½ì…
                wks.insert_rows(final_matrix, row=2)
                print(f"âœ… [ì„±ê³µ] {now_str} ê¸°ì¤€ ê°€ë¡œí˜• ë°ì´í„° ì‚½ì… ì™„ë£Œ!")

                # í–‰ ê°œìˆ˜ ê´€ë¦¬ (3ë‹¬ì¹˜ ìœ ì§€)
                total_rows = len(wks.get_all_values())
                if total_rows > MAX_ROWS:
                    wks.delete_rows(MAX_ROWS + 1, total_rows)
            except Exception as e:
                print(f"âŒ ì‹œíŠ¸ ì €ì¥ ì‹¤íŒ¨: {e}")
        else:
            print("âŒ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ í•˜ë‚˜ë„ ì—†ìŠµë‹ˆë‹¤. í˜ì´ì§€ êµ¬ì¡° ë˜ëŠ” ì°¨ë‹¨ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

        await browser.close()

if __name__ == "__main__":
    asyncio.run(get_danawa_data())
